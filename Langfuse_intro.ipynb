{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMicS9B9E3j3SjyAatg3W7t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njucs/notebook/blob/master/Langfuse_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**第一部分：Langfuse 简介和基本概念**\n",
        "\n",
        "1.  **什么是 Langfuse？**\n",
        "    *   解释 Langfuse 的核心概念：可观测性（Observability）和评估（Evaluation）。\n",
        "    *   强调 Langfuse 在 LLM 应用开发中的作用和价值。\n",
        "    *   对比传统应用开发和 LLM 应用开发的挑战。\n",
        "2.  **Langfuse 的主要功能：概览**\n",
        "    *   简要介绍 Langfuse 的核心功能：跟踪记录、可视化、评估、提示工程管理。\n",
        "    *   解释这些功能如何帮助开发者构建更好的 LLM 应用。\n",
        "3.  **安装和设置 Langfuse**\n",
        "    *   介绍如何安装 Langfuse SDK (Python)。\n",
        "    *   创建一个 Langfuse 帐户。\n",
        "    *   获取 API Key 和其他必要的配置。\n",
        "    *   运行一个简单的 Python 示例，展示如何将数据发送到 Langfuse。\n",
        "    *   **关键点：** 演示如何快速启动 Langfuse 并看到数据。\n",
        "\n",
        "**第二部分：核心功能详解：可观测性 (Observability)**\n",
        "\n",
        "1.  **跟踪和记录 LLM 调用**\n",
        "    *   使用 Langfuse SDK 跟踪 LLM 请求、响应和中间步骤。\n",
        "    *   解释如何使用 `trace`, `span`, `input`, `output` 等基本概念。\n",
        "    *   使用实际的代码示例演示如何跟踪简单的 LLM 调用。\n",
        "    *   **关键点：** 展示如何捕捉 LLM 调用的细节。\n",
        "2.  **可视化你的数据**\n",
        "    *   探索 Langfuse Web 界面中的仪表盘。\n",
        "    *   解释如何查看和理解关键指标，例如延迟、请求次数、错误率。\n",
        "    *   演示如何使用过滤器和搜索功能来查找特定的数据点。\n",
        "    *   **关键点：** 让用户明白如何通过可视化来了解应用的行为。\n",
        "3.  **上下文信息和元数据**\n",
        "    *   解释如何为跟踪记录添加上下文信息和元数据（例如，用户 ID、会话 ID、提示版本）。\n",
        "    *   演示如何使用这些信息来更深入地分析数据。\n",
        "    *   **关键点：** 说明上下文信息对于分析 LLM 应用的重要性。\n",
        "\n",
        "**第三部分：核心功能详解：评估 (Evaluation)**\n",
        "\n",
        "1.  **定义评估指标**\n",
        "    *   解释 Langfuse 中评估指标的概念。\n",
        "    *   演示如何定义自定义的评估指标（例如，准确率、相关性、流畅度）。\n",
        "    *   使用示例演示如何定义简单的评估指标。\n",
        "    *   **关键点：** 强调评估指标对于衡量 LLM 应用性能的重要性。\n",
        "2.  **自动化评估**\n",
        "    *   使用 Langfuse 自动评估模型输出。\n",
        "    *   解释如何将评估指标应用于记录的数据。\n",
        "    *   展示评估结果的呈现方式（例如，分数、图表）。\n",
        "    *   **关键点：** 展示如何快速评估 LLM 模型的性能。\n",
        "3.  **人工评估**\n",
        "    *   演示如何使用 Langfuse 进行人工评估。\n",
        "    *   解释如何添加人工评估结果到 Langfuse。\n",
        "    *   **关键点：** 说明人工评估对于细致分析 LLM 应用的重要性。\n",
        "\n",
        "**第四部分：进阶功能和最佳实践**\n",
        "\n",
        "1.  **提示工程管理**\n",
        "    *   介绍 Langfuse 如何帮助跟踪和管理不同的提示版本。\n",
        "    *   演示如何比较不同提示版本的性能。\n",
        "    *   **关键点：** 让用户理解提示工程管理的重要性。\n",
        "2.  **Langfuse 与其他工具的集成**\n",
        "    *   简要介绍 Langfuse 如何与其他工具（例如 LangChain、Hugging Face）集成。\n",
        "    *   **关键点：** 说明 Langfuse 的通用性和灵活性。\n",
        "3.  **最佳实践:**\n",
        "    *   分享一些使用 Langfuse 的最佳实践，例如如何有效地利用其功能、如何进行高效的调试和优化。\n",
        "    *   提供一些常用的调试和问题排查技巧。\n",
        "4.  **案例分析:**\n",
        "    *   展示一些实际的案例，演示 Langfuse 如何帮助开发者构建更好的 LLM 应用。\n",
        "\n",
        "**学习资源:**\n",
        "\n",
        "*   提供 Langfuse 官方文档的链接。\n",
        "*   提供一些额外的学习资源和教程链接。\n",
        "\n",
        "\n",
        "[更多介绍](https://langfuse.com/why)"
      ],
      "metadata": {
        "id": "ubA-y2RQsU1_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. 安装Langfuse"
      ],
      "metadata": {
        "id": "T-qtJVCJwa3U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# 首先，你需要安装 Langfuse 的 Python SDK。\n",
        "\n",
        "!pip install langfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb1YW15kxV4c",
        "outputId": "b371d300-0510-4678-d082-d2238dba7cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langfuse\n",
            "  Downloading langfuse-2.57.1-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting anyio<5.0.0,>=4.4.0 (from langfuse)\n",
            "  Downloading anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting backoff>=1.10.0 (from langfuse)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: httpx<1.0,>=0.15.4 in /usr/local/lib/python3.10/dist-packages (from langfuse) (0.28.1)\n",
            "Requirement already satisfied: idna<4.0,>=3.7 in /usr/local/lib/python3.10/dist-packages (from langfuse) (3.10)\n",
            "Requirement already satisfied: packaging<25.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langfuse) (24.2)\n",
            "Requirement already satisfied: pydantic<3.0,>=1.10.7 in /usr/local/lib/python3.10/dist-packages (from langfuse) (2.10.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langfuse) (2.32.3)\n",
            "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.10/dist-packages (from langfuse) (1.17.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.4.0->langfuse) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0.0,>=4.4.0->langfuse) (4.12.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1.0,>=0.15.4->langfuse) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1.0,>=0.15.4->langfuse) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0,>=1.10.7->langfuse) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langfuse) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langfuse) (2.2.3)\n",
            "Downloading langfuse-2.57.1-py3-none-any.whl (254 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.8/254.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: backoff, anyio, langfuse\n",
            "  Attempting uninstall: anyio\n",
            "    Found existing installation: anyio 3.7.1\n",
            "    Uninstalling anyio-3.7.1:\n",
            "      Successfully uninstalled anyio-3.7.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jupyter-server 1.24.0 requires anyio<4,>=3.1.0, but you have anyio 4.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed anyio-4.7.0 backoff-2.2.1 langfuse-2.57.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 接下来，你需要初始化 Langfuse，并连接到你的 Langfuse 服务器。\n",
        "# 你需要提供你的 Langfuse API 密钥和 Host URL。（新建Project -> settings -> API keys）\n",
        "# **注意:** 你需要提前安装并运行 Langfuse 服务器。\n",
        "\n",
        "from langfuse import Langfuse\n",
        "\n",
        "# 将 \"YOUR_LANGFUSE_PUBLIC_KEY\" 替换为你的 Langfuse API Key\n",
        "# 将 \"YOUR_LANGFUSE_HOST\" 替换为你的 Langfuse Host URL，一般是http://localhost:3000\n",
        "#langfuse = Langfuse(\n",
        "#    public_key=\"pk-lf-6e020669-deac-49b3-a285-26b357eaf7d4\",\n",
        "#    host=\"https://us.cloud.langfuse.com\"\n",
        "#)\n",
        "\n",
        "langfuse = Langfuse(\n",
        "  secret_key=\"sk-lf-ae9016c5-a52a-43f4-9480-957a0de37b62\",\n",
        "  public_key=\"pk-lf-0d034cbd-bb33-4e2c-afc8-c0abf68e7924\",\n",
        "  host=\"https://us.cloud.langfuse.com\"\n",
        ")"
      ],
      "metadata": {
        "id": "WzwR4Mkixsb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Hello World 一下**"
      ],
      "metadata": {
        "id": "r42zjRj2yCTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 为了演示 Langfuse 的使用，我们创建一个简单的 LLM 应用，它使用 Siliconflow API 来回答问题。\n",
        "\n",
        "# !pip install openai\n",
        "\n",
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ozx8oBYyqQW",
        "outputId": "3e1546fb-3f3c-420b-e1c4-515abf5fe358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.58.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.7.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=\"sk-tmqnbjqqtvgdobugtdcvrtnlnbtuqlhacyxgurbgndnokwva\", base_url=\"https://api.siliconflow.cn/v1\")\n",
        "\n",
        "def ask_llm(question):\n",
        "    response = client.chat.completions.create(\n",
        "        model='THUDM/glm-4-9b-chat',\n",
        "        messages=[\n",
        "            {'role': 'user',\n",
        "            'content': question}\n",
        "        ],\n",
        "        stream=True\n",
        "    )\n",
        "    return response\n",
        "\n",
        "answer = ask_llm(\"中国大模型行业2025年将会迎来哪些机遇和挑战\")\n",
        "\n",
        "for chunk in answer:\n",
        "    print(chunk.choices[0].delta.content, end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zSvhXfLyvvD",
        "outputId": "5ac3523e-eb65-4469-9d5c-ee3197afffce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "2025年，中国大模型行业预计将面临以下机遇和挑战：\n",
            "\n",
            "### 机遇：\n",
            "\n",
            "1. **技术成熟**：随着技术的不断进步，大模型的训练效率和准确性将进一步提高，为更多的应用场景提供支持。\n",
            "\n",
            "2. **政策支持**：中国政府在人工智能领域持续出台支持政策，为行业发展提供了良好的外部环境。\n",
            "\n",
            "3. **市场需求增长**：随着数字化转型的加速，企业和个人对于智能化解决方案的需求不断增加，为大模型提供了广阔的市场空间。\n",
            "\n",
            "4. **数据资源丰富**：中国拥有大量丰富的数据资源，这为训练高质量的大模型提供了必要条件。\n",
            "\n",
            "5. **国际合作**：大模型的研发和部署将促进中外企业的技术交流和合作，有利于行业的整体进步。\n",
            "\n",
            "### 挑战：\n",
            "\n",
            "1. **数据质量与隐私**：大模型训练需要大量数据，如何处理数据质量问题以及保护个人隐私将成为一大挑战。\n",
            "\n",
            "2. **算法伦理与公平性**：大模型可能存在偏见和 fairness 问题，如何确保算法的伦理性和公平性是行业需要面对的问题。\n",
            "\n",
            "3. **算力需求**：大模型的训练和运行需要巨大的算力支持，如何高效地利用有限的算力资源将是一个挑战。\n",
            "\n",
            "4. **合作竞争**：在快速发展的同时，行业内部可能存在过度竞争现象，如何实现协同创新将是企业需要考虑的问题。\n",
            "\n",
            "5. **国际环境**：在全球化背景下，国际政治经济环境的不确定性可能对中国大模型行业产生一定影响。\n",
            "\n",
            "6. **知识产权保护**：随着技术的快速发展，知识产权的保护和合理使用也是一个需要关注的议题。\n",
            "\n",
            "总之，2025年，中国大模型行业将迎来前所未有的发展机遇，同时也需要在技术、政策、市场等多个层面迎接一系列挑战。"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 Langfuse 来跟踪我们的 LLM 应用。\n",
        "# 创建一个 Trace 来记录用户的一次提问，创建一个 Span 来记录一次 OpenAI API 调用。\n",
        "# 每次调用都会有相应的 `start_span()`  `update_span()` 和 `end_span()`， 如下\n",
        "\n",
        "def ask_llm_with_langfuse(question):\n",
        "    # 创建一个 Trace\n",
        "    trace = langfuse.trace(name=\"问答机器人\")\n",
        "    # 创建一个 Span 来跟踪 OpenAI API 调用\n",
        "    span = trace.span(name=\"openai_call\")  # 修改：获取 span 对象，不使用 with\n",
        "    span.update(name = \"user_question\", input=question)\n",
        "    response = ask_llm(question)\n",
        "    span.update(name=\"llm_response\",output=response)\n",
        "    #span.end() # 显示结束 span\n",
        "    #trace.end()\n",
        "    return response\n",
        "\n",
        "question = \"Hello World～ 你是谁？\"\n",
        "answer = ask_llm_with_langfuse(question)\n",
        "print(f\"用户提问: {question}\")\n",
        "print(f\"AI回答:\\n\")\n",
        "for chunk in answer:\n",
        "    print(chunk.choices[0].delta.content, end='')\n",
        "\n",
        "\n",
        "# 打开 Langfuse 仪表板，查看刚才生成的 Trace 和 Span，查看每个 Span 中的事件和观测数据。\n",
        "# 可以看到，Langfuse 记录了 LLM 应用中的关键步骤，包括：\n",
        "# *   Trace 的名称\n",
        "# *   Span 的名称\n",
        "# *   Span 中的事件，例如用户提问和 OpenAI 的回答\n",
        "#\n",
        "# 你可以在 Langfuse 仪表板中查看这些数据，也可以使用 Langfuse API 来进行更深入的数据分析。"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXQXCoOyzHPp",
        "outputId": "a627910e-6f93-4318-a8bf-8ea94b723a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "用户提问: Hello World～ 你是谁？\n",
            "AI回答:\n",
            "\n",
            "\n",
            "Hello～我是人工智能助手 ChatGLM，很高兴见到你。我是基于清华大学 KEG 实验室和智谱 AI 公司于 2024 年共同训练的语言模型 GLM 开发的，我的任务是针对用户的问题和要求提供适当的答复和支持。"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 除了跟踪之外，Langfuse 还支持对 LLM 应用的输出进行评分和评估。\n",
        "# 例如，我们可以让用户手动对 LLM 回答的质量进行评分。\n",
        "\n",
        "def ask_llm_with_langfuse_and_score(question):\n",
        "    # 创建一个 Trace\n",
        "    trace = langfuse.trace(name=\"评分的问答机器人\")\n",
        "    # 创建一个 Span 来跟踪 OpenAI API 调用\n",
        "    span = trace.span(name=\"openai_call_and_score\")\n",
        "    span.update(name = \"user_question\", input=question)\n",
        "    response = ask_llm(question)\n",
        "    span.update(name=\"llm_response\",output=response)\n",
        "\n",
        "    score = input(\"请对AI的回答进行评分（1-5， 5分最高）\")\n",
        "    try:\n",
        "        span.score(name=\"response_quality\", value=int(score))\n",
        "    except:\n",
        "        print(\"评分格式错误！\")\n",
        "\n",
        "    return response\n",
        "\n",
        "question = \"请写一首关于冬天的诗\"\n",
        "answer = ask_llm_with_langfuse_and_score(question)\n",
        "print(f\"用户提问: {question}\")\n",
        "print(f\"AI回答:\")\n",
        "for chunk in answer:\n",
        "    print(chunk.choices[0].delta.content, end='')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5BX6TdwyKpE",
        "outputId": "64a04077-baf7-4fe8-f05c-59f8f9e7df61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "请对AI的回答进行评分（1-5， 5分最高）3\n",
            "用户提问: 请写一首关于冬天的诗\n",
            "AI回答:\n",
            "\n",
            "\n",
            "冬雪纷飞舞飘渺，\n",
            "银装素裹拥寒潮。\n",
            "寒梅傲雪斗风雪，\n",
            "世界一片寂静悄。\n",
            "\n",
            "冰封河面cimento，\n",
            "白雪覆盖枝头翘。\n",
            "街头巷尾堆雪人，\n",
            "笑声欢歌逐风飘。\n",
            "\n",
            "太阳慵懒挂天空，\n",
            "余晖映照霜花映。\n",
            "夜幕低垂璨星辰，\n",
            "寒夜漫长星闪烁。\n",
            "\n",
            "炉火熊熊映脸庞，\n",
            "暖意盎然心头荡。\n",
            "雪花轻盈舞飘飘，\n",
            "暖冬模样映人心。\n",
            "\n",
            "踏雪寻踪观景致，\n",
            "泡一壶茶话温暖。\n",
            "冬日美景入画卷，\n",
            "岁月静好存心上。"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  **1. 安装 Langfuse 和发送简单的追踪**\n",
        "\n",
        "目标：\n",
        "- 学习如何安装 Langfuse SDK。\n",
        "- 创建一个 Langfuse 账户并获取 API Key。\n",
        "- 发送一个简单的追踪事件到 Langfuse。"
      ],
      "metadata": {
        "id": "ANfw8yExCU7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 安装 Langfuse SDK\n",
        "# pip install langfuse\n",
        "\n",
        "# 2. 导入 Langfuse\n",
        "from langfuse import Langfuse\n",
        "\n",
        "# 3. 初始化 Langfuse 客户端\n",
        "# 请替换为你的实际 API Key\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 4. 创建一个追踪\n",
        "trace = langfuse.trace(name=\"my-first-trace\")\n",
        "\n",
        "# 5. 创建一个 span (可选，但推荐)\n",
        "span = trace.span(name=\"my-first-span\")\n",
        "\n",
        "# 6. 发送一些输入和输出数据\n",
        "span.input(data={\"prompt\": \"Hello Langfuse!\"})\n",
        "span.output(data={\"response\": \"Hello World!\"})\n",
        "\n",
        "# 7. 完成 span\n",
        "span.end()\n",
        "\n",
        "# 8. 完成追踪\n",
        "trace.end()\n",
        "\n",
        "\n",
        "print(\"追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "5cp1I1n5Cngd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. 追踪 LLM 调用**\n",
        "\n",
        "目标：\n",
        "- 学习如何使用 Langfuse 跟踪 LLM 的请求和响应。\n",
        "- 理解 input 和 output 函数的用法。\n",
        "- 了解如何将 LLM 调用中的上下文信息传递给 Langfuse。"
      ],
      "metadata": {
        "id": "wk1z3I-cCwGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import openai\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\"  # 请替换为你的 OpenAI API Key\n",
        "\n",
        "# 1. 创建一个追踪\n",
        "trace = langfuse.trace(name=\"llm-call-trace\")\n",
        "\n",
        "# 2. 创建一个 span，表示 LLM 调用\n",
        "span = trace.span(name=\"openai-chat-completion\")\n",
        "\n",
        "# 3. 定义 LLM 的请求参数\n",
        "prompt = \"请用中文总结一下：Langfuse 是一个可观测性和评估工具。\"\n",
        "llm_params = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "}\n",
        "\n",
        "# 4. 发送 LLM 请求并记录输入\n",
        "span.input(data={\"llm_params\": llm_params})\n",
        "\n",
        "# 5. 执行 LLM 调用\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(**llm_params)\n",
        "    # 6. 记录 LLM 的响应\n",
        "    span.output(data={\"response\": response.to_dict()})\n",
        "except Exception as e:\n",
        "    span.output(data={\"error\": str(e)})\n",
        "    span.error(e) # 标记span为错误\n",
        "    print(f\"LLM调用失败: {e}\")\n",
        "finally:\n",
        "  # 7. 完成 span\n",
        "  span.end()\n",
        "\n",
        "\n",
        "# 8. 完成追踪\n",
        "trace.end()\n",
        "\n",
        "print(\"LLM调用追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "wmd95LxtC7rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 使用上下文信息**\n",
        "\n",
        "目标：\n",
        "- 学习如何为 Langfuse 的追踪和 Span 添加上下文信息。\n",
        "- 理解 metadata 和 user_id 的用法。\n",
        "- 了解上下文信息如何帮助分析和过滤数据。"
      ],
      "metadata": {
        "id": "c4CamHaUC8sh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import openai\n",
        "import uuid\n",
        "import time\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\" # 请替换为你的 OpenAI API Key\n",
        "\n",
        "# 1. 模拟用户 ID\n",
        "user_id = str(uuid.uuid4())\n",
        "\n",
        "# 2. 创建一个追踪，并添加上下文信息\n",
        "trace = langfuse.trace(\n",
        "    name=\"context-trace\",\n",
        "    user_id=user_id,\n",
        "    metadata={\n",
        "        \"user_location\": \"New York\",\n",
        "        \"user_browser\": \"Chrome\",\n",
        "        \"timestamp\": time.time()\n",
        "    }\n",
        ")\n",
        "\n",
        "# 3. 创建一个 span，并添加上下文信息\n",
        "span = trace.span(\n",
        "    name=\"openai-chat-completion-with-context\",\n",
        "    metadata={\"model_version\": \"v1.0\"}\n",
        ")\n",
        "\n",
        "# 4. 定义 LLM 的请求参数\n",
        "prompt = \"请用英文总结一下：Langfuse 是一个可观测性和评估工具。\"\n",
        "llm_params = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "}\n",
        "\n",
        "# 5. 发送 LLM 请求并记录输入\n",
        "span.input(data={\"llm_params\": llm_params})\n",
        "\n",
        "# 6. 执行 LLM 调用\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(**llm_params)\n",
        "    # 7. 记录 LLM 的响应\n",
        "    span.output(data={\"response\": response.to_dict()})\n",
        "except Exception as e:\n",
        "     span.output(data={\"error\": str(e)})\n",
        "     span.error(e) # 标记span为错误\n",
        "     print(f\"LLM调用失败: {e}\")\n",
        "finally:\n",
        "  # 8. 完成 span\n",
        "  span.end()\n",
        "\n",
        "# 9. 完成追踪\n",
        "trace.end()\n",
        "\n",
        "print(\"带有上下文信息的追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "cP8S7iJ5DGaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 定义和使用评估指标**\n",
        "\n",
        "目标：\n",
        "- 学习如何在 Langfuse 中定义自定义评估指标。\n",
        "- 了解如何将评估指标应用于追踪数据。\n",
        "- 理解 score 函数的用法。"
      ],
      "metadata": {
        "id": "MsHh1WlWZBuU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import openai\n",
        "import time\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\" # 请替换为你的 OpenAI API Key\n",
        "\n",
        "# 1. 创建一个追踪\n",
        "trace = langfuse.trace(name=\"evaluation-trace\")\n",
        "\n",
        "# 2. 创建一个 span\n",
        "span = trace.span(name=\"openai-chat-completion-evaluation\")\n",
        "\n",
        "# 3. 定义 LLM 的请求参数\n",
        "prompt = \"请用中文总结一下：Langfuse 的评估功能。\"\n",
        "llm_params = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "}\n",
        "\n",
        "# 4. 发送 LLM 请求并记录输入\n",
        "span.input(data={\"llm_params\": llm_params})\n",
        "\n",
        "# 5. 执行 LLM 调用\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(**llm_params)\n",
        "    llm_response = response.choices[0].message.content\n",
        "    # 6. 记录 LLM 的响应\n",
        "    span.output(data={\"response\": llm_response})\n",
        "\n",
        "    # 7. 定义评估指标\n",
        "    # 假设我们定义一个简单的 “是否包含关键字” 指标\n",
        "    keywords = [\"评估\", \"指标\", \"工具\"]\n",
        "    score = 0\n",
        "    for keyword in keywords:\n",
        "      if keyword in llm_response:\n",
        "        score += 1\n",
        "\n",
        "    # 8. 应用评估指标\n",
        "    span.score(name=\"keyword_match\", value=score / len(keywords), metadata={\"keywords\":keywords})\n",
        "\n",
        "except Exception as e:\n",
        "    span.output(data={\"error\": str(e)})\n",
        "    span.error(e) # 标记span为错误\n",
        "    print(f\"LLM调用失败: {e}\")\n",
        "finally:\n",
        "  # 9. 完成 span\n",
        "  span.end()\n",
        "\n",
        "# 10. 完成追踪\n",
        "trace.end()\n",
        "\n",
        "print(\"带有评估指标的追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "d2KV4YgeZIDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. 人工评估**\n",
        "\n",
        "目标:\n",
        "- 学习如何使用 Langfuse 进行人工评估。\n",
        "- 理解如何将人工评估结果添加到 Langfuse。\n",
        "- 了解人工评估如何帮助提高 LLM 应用的质量。"
      ],
      "metadata": {
        "id": "OSX1uTJPZKio"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import openai\n",
        "import time\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\" # 请替换为你的 OpenAI API Key\n",
        "\n",
        "# 1. 创建一个追踪\n",
        "trace = langfuse.trace(name=\"human-evaluation-trace\")\n",
        "\n",
        "# 2. 创建一个 span\n",
        "span = trace.span(name=\"openai-chat-completion-human-evaluation\")\n",
        "\n",
        "# 3. 定义 LLM 的请求参数\n",
        "prompt = \"请用一句话概括：Langfuse 是什么？\"\n",
        "llm_params = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "}\n",
        "\n",
        "# 4. 发送 LLM 请求并记录输入\n",
        "span.input(data={\"llm_params\": llm_params})\n",
        "\n",
        "# 5. 执行 LLM 调用\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(**llm_params)\n",
        "    llm_response = response.choices[0].message.content\n",
        "    # 6. 记录 LLM 的响应\n",
        "    span.output(data={\"response\": llm_response})\n",
        "\n",
        "    # 7. 模拟人工评估（在实际应用中，这部分需要人工完成）\n",
        "    # 假设人工评估结果如下\n",
        "    human_score = 4 # 假设满分是5分\n",
        "    human_feedback = \"总体来说，总结的还不错，但可以更简洁一些。\"\n",
        "\n",
        "    # 8. 添加人工评估结果\n",
        "    span.score(name=\"human_rating\", value=human_score / 5, metadata={\"feedback\": human_feedback})\n",
        "\n",
        "except Exception as e:\n",
        "    span.output(data={\"error\": str(e)})\n",
        "    span.error(e) # 标记span为错误\n",
        "    print(f\"LLM调用失败: {e}\")\n",
        "finally:\n",
        "  # 9. 完成 span\n",
        "  span.end()\n",
        "\n",
        "# 10. 完成追踪\n",
        "trace.end()\n",
        "\n",
        "print(\"带有人工评估的追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "AZu9NXrxZUnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6. 提示工程管理**\n",
        "\n",
        "目标:\n",
        "- 学习如何使用 Langfuse 管理不同的提示版本。\n",
        "- 了解如何使用 input 来记录不同的提示。\n",
        "- 理解如何比较不同提示版本的性能。"
      ],
      "metadata": {
        "id": "Z_1eZO89ZVdy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import openai\n",
        "import time\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\"  # 请替换为你的 OpenAI API Key\n",
        "\n",
        "# 定义不同的提示版本\n",
        "prompts = {\n",
        "    \"v1\": \"请用一句话总结一下：Langfuse 是什么？\",\n",
        "    \"v2\": \"请简要概括 Langfuse 的主要功能。\",\n",
        "    \"v3\": \"用最精炼的语言描述一下 Langfuse 的核心价值。\"\n",
        "}\n",
        "\n",
        "for version, prompt in prompts.items():\n",
        "    # 1. 创建一个追踪\n",
        "    trace = langfuse.trace(name=\"prompt-engineering-trace\")\n",
        "\n",
        "    # 2. 创建一个 span\n",
        "    span = trace.span(name=\"openai-chat-completion-prompt-version\")\n",
        "\n",
        "    # 3. 定义 LLM 的请求参数\n",
        "    llm_params = {\n",
        "        \"model\": \"gpt-3.5-turbo\",\n",
        "        \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "    }\n",
        "\n",
        "    # 4. 发送 LLM 请求并记录输入\n",
        "    span.input(data={\"prompt_version\": version, \"llm_params\": llm_params})\n",
        "\n",
        "    # 5. 执行 LLM 调用\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(**llm_params)\n",
        "        llm_response = response.choices[0].message.content\n",
        "        # 6. 记录 LLM 的响应\n",
        "        span.output(data={\"response\": llm_response})\n",
        "\n",
        "    except Exception as e:\n",
        "       span.output(data={\"error\": str(e)})\n",
        "       span.error(e) # 标记span为错误\n",
        "       print(f\"LLM调用失败: {e}\")\n",
        "    finally:\n",
        "        # 7. 完成 span\n",
        "        span.end()\n",
        "\n",
        "\n",
        "    # 8. 完成追踪\n",
        "    trace.end()\n",
        "\n",
        "print(\"不同提示版本的追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "hsMnECORZgGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **7. 使用 Event 功能**\n",
        "\n",
        "目标:\n",
        "- 学习如何使用 Langfuse 的 event 功能记录非 LLM 操作的事件。\n",
        "- 理解 event 和 span 的区别。\n",
        "- 了解 event 如何帮助你构建完整的应用上下文。"
      ],
      "metadata": {
        "id": "jzKxIgJnZkFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 1. 模拟用户 ID\n",
        "user_id = str(uuid.uuid4())\n",
        "\n",
        "# 2. 创建一个追踪\n",
        "trace = langfuse.trace(name=\"event-trace\", user_id=user_id)\n",
        "\n",
        "# 3. 记录一个用户登录事件\n",
        "langfuse.event(\n",
        "    name=\"user_login\",\n",
        "    trace_id=trace.id, # 将事件关联到当前trace\n",
        "    input={\"login_method\": \"email\"},\n",
        "    metadata={\"ip_address\": \"127.0.0.1\"}\n",
        ")\n",
        "time.sleep(1)\n",
        "\n",
        "# 4. 模拟一些后台处理\n",
        "langfuse.event(\n",
        "    name=\"start_data_processing\",\n",
        "    trace_id=trace.id, # 将事件关联到当前trace\n",
        "    metadata={\"job_id\": str(uuid.uuid4())}\n",
        ")\n",
        "time.sleep(2)\n",
        "\n",
        "# 5. 创建一个 span，表示 LLM 调用\n",
        "span = trace.span(name=\"openai-chat-completion-event\")\n",
        "\n",
        "# 6. 定义 LLM 的请求参数\n",
        "prompt = \"请简要描述一下 Langfuse.\"\n",
        "llm_params = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "}\n",
        "\n",
        "# 7. 发送 LLM 请求并记录输入\n",
        "span.input(data={\"llm_params\": llm_params})\n",
        "\n",
        "# 8. 执行 LLM 调用\n",
        "try:\n",
        "    import openai\n",
        "    openai.api_key = \"YOUR_OPENAI_API_KEY\" # 请替换为你的 OpenAI API Key\n",
        "    response = openai.ChatCompletion.create(**llm_params)\n",
        "    # 9. 记录 LLM 的响应\n",
        "    span.output(data={\"response\": response.to_dict()})\n",
        "\n",
        "except Exception as e:\n",
        "    span.output(data={\"error\": str(e)})\n",
        "    span.error(e) # 标记span为错误\n",
        "    print(f\"LLM调用失败: {e}\")\n",
        "finally:\n",
        "  # 10. 完成 span\n",
        "  span.end()\n",
        "\n",
        "# 11. 记录一个数据处理完成事件\n",
        "langfuse.event(\n",
        "    name=\"end_data_processing\",\n",
        "     trace_id=trace.id, # 将事件关联到当前trace\n",
        "    metadata={\"status\": \"success\"}\n",
        ")\n",
        "time.sleep(0.5)\n",
        "# 12. 完成追踪\n",
        "trace.end()\n",
        "\n",
        "print(\"带有事件的追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "e2YeqVCFZqLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **8. 使用 Batch 方法批量发送数据**\n",
        "\n",
        "目标:\n",
        "- 学习如何使用 Langfuse 的 batch 方法批量发送追踪、span 和事件数据。\n",
        "- 理解批量发送数据的好处（例如，减少网络请求，提高效率）。\n",
        "- 了解如何使用 batch 方法处理大量数据。"
      ],
      "metadata": {
        "id": "YPyDltylZvJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import openai\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\" # 请替换为你的 OpenAI API Key\n",
        "\n",
        "num_traces = 10\n",
        "\n",
        "with langfuse.batch() as batch:\n",
        "    for i in range(num_traces):\n",
        "        # 1. 创建一个追踪\n",
        "        trace_id = str(uuid.uuid4())\n",
        "        trace = batch.trace(\n",
        "            name=f\"batch-trace-{i}\",\n",
        "            id=trace_id,\n",
        "            user_id = str(uuid.uuid4())\n",
        "        )\n",
        "\n",
        "\n",
        "        # 2. 记录一个用户登录事件\n",
        "        batch.event(\n",
        "            name=\"user_login\",\n",
        "            trace_id=trace.id, # 将事件关联到当前trace\n",
        "            input={\"login_method\": \"email\"},\n",
        "            metadata={\"ip_address\": \"127.0.0.1\"}\n",
        "        )\n",
        "\n",
        "        # 3. 创建一个 span\n",
        "        span = trace.span(name=\"openai-chat-completion-batch\")\n",
        "\n",
        "        # 4. 定义 LLM 的请求参数\n",
        "        prompt = f\"请简单描述一下 Langfuse, 这是第 {i} 个请求.\"\n",
        "        llm_params = {\n",
        "            \"model\": \"gpt-3.5-turbo\",\n",
        "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "        }\n",
        "\n",
        "        # 5. 发送 LLM 请求并记录输入\n",
        "        span.input(data={\"llm_params\": llm_params})\n",
        "\n",
        "        # 6. 执行 LLM 调用\n",
        "        try:\n",
        "           response = openai.ChatCompletion.create(**llm_params)\n",
        "           # 7. 记录 LLM 的响应\n",
        "           span.output(data={\"response\": response.to_dict()})\n",
        "        except Exception as e:\n",
        "           span.output(data={\"error\": str(e)})\n",
        "           span.error(e) # 标记span为错误\n",
        "           print(f\"LLM调用失败: {e}\")\n",
        "        finally:\n",
        "           # 8. 完成 span\n",
        "           span.end()\n",
        "        # 9. 完成追踪\n",
        "        trace.end()\n",
        "\n",
        "\n",
        "\n",
        "print(f\"{num_traces} 个带有追踪、事件和Span的batch数据已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "HFksvZ8_Z1g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **9. 错误处理与异常捕获**\n",
        "\n",
        "目标:\n",
        "- 学习如何在 Langfuse 中有效地处理 LLM 调用过程中可能出现的错误和异常。\n",
        "- 理解 span.error() 方法的用法。\n",
        "- 了解错误信息如何帮助调试和改进你的 LLM 应用。"
      ],
      "metadata": {
        "id": "0uzWND-IZ4NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import openai\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\"  # 请替换为你的 OpenAI API Key\n",
        "\n",
        "# 1. 创建一个追踪\n",
        "trace = langfuse.trace(name=\"error-handling-trace\")\n",
        "\n",
        "# 2. 创建一个 span\n",
        "span = trace.span(name=\"openai-chat-completion-error\")\n",
        "\n",
        "# 3. 定义 LLM 的请求参数\n",
        "prompt = \"请用中文总结一下：Langfuse 的错误处理功能。\"\n",
        "llm_params = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
        "    \"temperature\": 100 #故意设置一个不合理的值，大概率会导致出错\n",
        "}\n",
        "\n",
        "\n",
        "# 4. 发送 LLM 请求并记录输入\n",
        "span.input(data={\"llm_params\": llm_params})\n",
        "\n",
        "# 5. 执行 LLM 调用 (使用 try...except 块来捕获错误)\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(**llm_params)\n",
        "    llm_response = response.choices[0].message.content\n",
        "    # 6. 记录 LLM 的响应\n",
        "    span.output(data={\"response\": llm_response})\n",
        "\n",
        "except Exception as e:\n",
        "    # 7. 捕获异常并记录错误信息\n",
        "    span.output(data={\"error\": str(e)})\n",
        "    span.error(e)\n",
        "    print(f\"LLM调用失败: {e}\")\n",
        "finally:\n",
        "    # 8. 完成 span\n",
        "    span.end()\n",
        "\n",
        "\n",
        "# 9. 完成追踪\n",
        "trace.end()\n",
        "\n",
        "print(\"带有错误处理的追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "qz9QFCDsZ-9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **10. Langfuse 与 LangChain 集成**\n",
        "\n",
        "目标:\n",
        "- 学习如何将 Langfuse 与 LangChain 集成，追踪 LangChain 的执行流程。\n",
        "- 理解 Langfuse 如何帮助你分析 LangChain 的中间步骤。\n",
        "- 了解如何使用 Langfuse 来调试和优化 LangChain 应用。"
      ],
      "metadata": {
        "id": "lXmQU7UiaCx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langfuse.callback import LangfuseCallbackHandler\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY\" # 请替换为你的 OpenAI API Key\n",
        "\n",
        "# 1. 创建一个 LangfuseCallbackHandler\n",
        "langfuse_callback = LangfuseCallbackHandler(langfuse=langfuse)\n",
        "\n",
        "# 2. 初始化 LLM\n",
        "llm = OpenAI(temperature=0.9, callbacks=[langfuse_callback])\n",
        "\n",
        "# 3. 创建 PromptTemplate\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=\"你是一个有用的助手，请回答这个问题：{question}\"\n",
        ")\n",
        "\n",
        "# 4. 创建 LLMChain\n",
        "chain = LLMChain(llm=llm, prompt=prompt, callbacks=[langfuse_callback])\n",
        "\n",
        "# 5. 执行链条并传递追踪ID\n",
        "trace_id = str(uuid.uuid4())\n",
        "\n",
        "result = chain.run(question=\"Langfuse 是什么？\", trace_id=trace_id)\n",
        "\n",
        "print(\"LLM Chain 执行结果：\", result)\n",
        "\n",
        "# 6. 使用 Agent 工具\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm, callbacks=[langfuse_callback])\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True, callbacks=[langfuse_callback])\n",
        "try:\n",
        "    agent_result = agent.run(\"最近的图灵奖得主是谁？他们得奖时多少岁？\", trace_id=trace_id)\n",
        "    print(\"Agent 执行结果：\", agent_result)\n",
        "except Exception as e:\n",
        "    print(f\"Agent执行失败：{e}\")\n",
        "\n",
        "print(\"带有 LangChain 集成的追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "XiT0javFaJYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **11. 使用 Client API 直接发送自定义数据**\n",
        "\n",
        "目标:\n",
        "- 学习如何使用 Langfuse 的 Client API 直接发送自定义数据。\n",
        "- 理解 langfuse.client.log() 方法的用法。\n",
        "- 了解直接发送数据与使用 trace/span 的区别和应用场景。"
      ],
      "metadata": {
        "id": "lALo4V7eaMia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 1. 记录一个自定义事件\n",
        "event_id = str(uuid.uuid4())\n",
        "langfuse.client.log(\n",
        "    name=\"custom_event_1\",\n",
        "    input={\"event_type\": \"system_alert\"},\n",
        "    metadata={\"severity\": \"high\", \"timestamp\": time.time()},\n",
        "     id = event_id\n",
        ")\n",
        "\n",
        "time.sleep(1)\n",
        "\n",
        "# 2. 记录另一个自定义事件\n",
        "langfuse.client.log(\n",
        "    name=\"custom_event_2\",\n",
        "    input={\"event_type\": \"user_action\", \"user_id\": str(uuid.uuid4())},\n",
        "    metadata={\"action\": \"button_click\"},\n",
        "    id=str(uuid.uuid4())\n",
        ")\n",
        "\n",
        "# 3. 记录一个错误事件\n",
        "langfuse.client.log(\n",
        "    name=\"system_error\",\n",
        "    level=\"error\", # 支持设置 level 类型\n",
        "    input={\"error_code\": 500, \"error_message\": \"Internal Server Error\"},\n",
        "    metadata={\"component\": \"database\", \"timestamp\": time.time()},\n",
        "     id=str(uuid.uuid4())\n",
        ")\n",
        "\n",
        "# 4. 可以使用自定义 level 的事件\n",
        "langfuse.client.log(\n",
        "    name=\"custom_level_event\",\n",
        "     level=\"warning\", # 支持设置 level 类型\n",
        "    input={\"message\": \"Something is not right\", },\n",
        "    metadata={\"component\": \"API\", \"timestamp\": time.time()},\n",
        "      id=str(uuid.uuid4())\n",
        ")\n",
        "\n",
        "print(\"自定义数据已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "rugiEkgMaTNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **12. 使用 Update 方法修改已记录的数据**\n",
        "\n",
        "目标:\n",
        "- 学习如何使用 Langfuse 的 update 方法来修改已记录的 span 和事件数据。\n",
        "- 理解 update 方法的参数和用法。\n",
        "- 了解何时使用 update 方法来动态更新数据。"
      ],
      "metadata": {
        "id": "fgpiWoEvaWtC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langfuse import Langfuse\n",
        "import openai\n",
        "import time\n",
        "import uuid\n",
        "\n",
        "# 初始化 Langfuse\n",
        "langfuse = Langfuse(\n",
        "    public_key=\"YOUR_PUBLIC_KEY\",\n",
        "    secret_key=\"YOUR_SECRET_KEY\"\n",
        ")\n",
        "\n",
        "# 初始化 OpenAI 客户端\n",
        "openai.api_key = \"YOUR_OPENAI_API_KEY\" # 请替换为你的 OpenAI API Key\n",
        "\n",
        "# 1. 创建一个追踪\n",
        "trace = langfuse.trace(name=\"update-trace\")\n",
        "\n",
        "# 2. 创建一个 span，表示 LLM 调用\n",
        "span = trace.span(name=\"openai-chat-completion-update\")\n",
        "\n",
        "# 3. 定义 LLM 的请求参数\n",
        "prompt = \"请简单描述一下 Langfuse。\"\n",
        "llm_params = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
        "}\n",
        "\n",
        "# 4. 发送 LLM 请求并记录输入\n",
        "span.input(data={\"llm_params\": llm_params, \"initial_status\":\"pending\"})\n",
        "\n",
        "# 5. 执行 LLM 调用\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(**llm_params)\n",
        "    llm_response = response.choices[0].message.content\n",
        "    # 6. 记录 LLM 的响应\n",
        "    span.output(data={\"response\": llm_response})\n",
        "    # 7. 更新 span 数据\n",
        "    time.sleep(1) # 模拟一些延迟\n",
        "    langfuse.update(\n",
        "        id=span.id,\n",
        "         status_message=\"LLM call success\",\n",
        "         metadata={\"final_status\":\"success\", \"updated_at\": time.time()}\n",
        "    )\n",
        "\n",
        "except Exception as e:\n",
        "    # 8. 捕获异常并记录错误信息\n",
        "    span.output(data={\"error\": str(e)})\n",
        "    span.error(e)\n",
        "    # 9. 更新 span 数据，标记为失败\n",
        "    langfuse.update(\n",
        "        id = span.id,\n",
        "        status_message=\"LLM call failed\",\n",
        "       metadata={\"final_status\":\"failed\", \"updated_at\": time.time()}\n",
        "    )\n",
        "    print(f\"LLM调用失败: {e}\")\n",
        "finally:\n",
        "    # 10. 完成 span\n",
        "    span.end()\n",
        "\n",
        "# 11. 创建一个 event\n",
        "event_id = str(uuid.uuid4())\n",
        "langfuse.event(\n",
        "    name=\"user_action\",\n",
        "    input={\"action_type\": \"button_click\", \"user_id\": str(uuid.uuid4())},\n",
        "    metadata={\"timestamp\": time.time()},\n",
        "      trace_id = trace.id,\n",
        "    id = event_id\n",
        ")\n",
        "time.sleep(1)\n",
        "# 12. 更新 event 数据\n",
        "langfuse.update(\n",
        "    id = event_id,\n",
        "     input={\"action_type\": \"button_click\", \"user_id\": str(uuid.uuid4()), \"final\":True},\n",
        "    metadata={\"updated_at\": time.time(), \"message\":\"Event is finished.\"}\n",
        ")\n",
        "# 13. 完成追踪\n",
        "trace.end()\n",
        "\n",
        "print(\"带有更新数据的追踪已发送到 Langfuse!\")"
      ],
      "metadata": {
        "id": "seRnZQHdad_-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}