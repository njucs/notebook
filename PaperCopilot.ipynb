{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOT8zivmhxVC3byXgH0ySPh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njucs/notebook/blob/master/PaperCopilot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 scikit-learn sentence-transformers google-search-results transformers"
      ],
      "metadata": {
        "id": "UsEeU6gezZrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTQtRrNxtBFL",
        "outputId": "cb2f1026-96f9-41fd-9f1f-c866d299c369"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "related papers:  \n",
            "```json\n",
            "[\n",
            "  {\n",
            "    \"title\": \"Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal Utterances\",\n",
            "    \"authors\": \"Hanlei Zhang, Hua Xu, Fei Long, Xin Wang, Kai Gao\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"Exploring Chain-of-Thought for Multi-modal Metaphor Detection\",\n",
            "    \"authors\": \"Yanzhi Xu, Yueying Hua, Shichen Li, Zhongqing Wang\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"DeVAn: Dense Video Annotation for Video-Language Models\",\n",
            "    \"authors\": \"Tingkai Liu, Yunzhe Tao, Haogeng Liu, Qihang Fang, Ding Zhou, Huaibo Huang, Ran He, Hongxia Yang\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"MinPrompt: Graph-based Minimal Prompt Data Augmentation for Few-shot Question Answering\",\n",
            "    \"authors\": \"Xiusi Chen, Jyun-Yu Jiang, Wei-Cheng Chang, Cho-Jui Hsieh, Hsiang-Fu Yu, Wei Wang\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"SportsMetrics: Blending Text and Numerical Data to Understand Information Fusion in LLMs\",\n",
            "    \"authors\": \"Yebowen Hu, Kaiqiang Song, Sangwoo Cho, Xiaoyang Wang, Hassan Foroosh, Dong Yu, Fei Liu\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"SciMON: Scientific Inspiration Machines Optimized for Novelty\",\n",
            "    \"authors\": \"Qingyun Wang, Doug Downey, Heng Ji, Tom Hope\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"Expedited Training of Visual Conditioned Language Generation via Redundancy Reduction\",\n",
            "    \"authors\": \"Yiren Jian, Tingkai Liu, Yunzhe Tao, Chunhui Zhang, Soroush Vosoughi, Hongxia Yang\"\n",
            "  },\n",
            "  {\n",
            "    \"title\": \"\",\n",
            "    \"authors\": \"\"\n",
            "  }\n",
            "]\n",
            "```\n",
            "JSON 解析错误\n",
            "Found 0 relevant papers using LLM.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from googlesearch import search\n",
        "from transformers import pipeline\n",
        "import json\n",
        "import os\n",
        "\n",
        "# 替换成你的API密钥，或者使用环境变量\n",
        "API_KEY = os.getenv('SILICONFLOW_API_KEY', 'sk-aerqsdefgpftbyerwomejvrrhgfkpgrbouhzwklhwbruuitc')\n",
        "BASE_URL = \"https://api.siliconflow.cn/v1/chat/completions\"\n",
        "\n",
        "\n",
        "# 定义大模型调用类\n",
        "class CallLLM:\n",
        "    def __init__(self):\n",
        "        self.url = BASE_URL\n",
        "        self.headers = {\n",
        "            \"Authorization\": f\"Bearer {API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "\n",
        "    def call(self, model_name, prompt):\n",
        "        payload = {\n",
        "            \"model\": model_name,\n",
        "            \"messages\": [\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": [\n",
        "                        {\n",
        "                            \"type\": \"text\",\n",
        "                            \"text\": prompt\n",
        "                        }\n",
        "                    ]\n",
        "                }\n",
        "            ],\n",
        "            \"stream\": False,\n",
        "            \"max_tokens\": 1024, # 可以适当增加 max_tokens\n",
        "            \"stop\": [\"null\"],\n",
        "            \"temperature\": 0.7,\n",
        "            \"top_p\": 0.7,\n",
        "            \"top_k\": 50,\n",
        "            \"frequency_penalty\": 0.5,\n",
        "            \"n\": 1,\n",
        "            \"response_format\": {\"type\": \"text\"}\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(self.url, json=payload, headers=self.headers)\n",
        "            response.raise_for_status()\n",
        "            return response.json()\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"API 请求错误: {e}\")\n",
        "            return None\n",
        "\n",
        "\n",
        "# 定义大模型类\n",
        "class Model:\n",
        "    def __init__(self, model_name, call_llm):\n",
        "        self.model_name = model_name\n",
        "        self.call_llm = call_llm\n",
        "\n",
        "    def generate_response(self, input_text):\n",
        "        response_data = self.call_llm.call(self.model_name, input_text)\n",
        "        if response_data and \"choices\" in response_data and response_data[\"choices\"]:\n",
        "          return response_data[\"choices\"][0][\"message\"][\"content\"]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "# 1. 使用大模型抽取相关论文列表\n",
        "def extract_relevant_papers_with_llm(html_content, query, llm_model):\n",
        "    prompt = f\"\"\"\n",
        "    你是一个信息抽取专家，请从以下 HTML 文本中识别并提取与用户查询相关的论文列表。\n",
        "    论文列表一般包含每篇论文的标题和作者信息。\n",
        "    用户查询：{query}\n",
        "    请以 JSON 格式返回提取结果，JSON 格式如下：\n",
        "    [\n",
        "      {{\n",
        "        \"title\": \"论文标题1\",\n",
        "        \"authors\": \"作者1, 作者2\"\n",
        "      }},\n",
        "      {{\n",
        "        \"title\": \"论文标题2\",\n",
        "        \"authors\": \"作者3\"\n",
        "      }},\n",
        "       ...\n",
        "    ]\n",
        "    如果找不到相关论文，请返回空列表 []。\n",
        "\n",
        "    HTML 文本：\n",
        "    {html_content}\n",
        "    \"\"\"\n",
        "\n",
        "    response_text = llm_model.generate_response(prompt)\n",
        "    print(\"related papers: \", response_text)\n",
        "    if response_text:\n",
        "        try:\n",
        "            papers = json.loads(response_text)\n",
        "            if isinstance(papers, list):\n",
        "               return papers\n",
        "        except json.JSONDecodeError:\n",
        "            print(\"JSON 解析错误\")\n",
        "    return []\n",
        "\n",
        "\n",
        "# 3. 论文内容搜索\n",
        "def search_paper_content(title):\n",
        "    search_results = search(title, num_results=3)\n",
        "    for url in search_results:\n",
        "      try:\n",
        "        response = requests.get(url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        text_content = ' '.join([p.text for p in soup.find_all('p')])\n",
        "        if text_content:\n",
        "            return text_content\n",
        "      except requests.exceptions.RequestException as e:\n",
        "         print(f\"Failed to fetch {url}: {e}\")\n",
        "    return None\n",
        "\n",
        "# 4. 论文观点归纳\n",
        "def summarize_paper_content(text, summarizer):\n",
        "    try:\n",
        "        summary = summarizer(text, max_length=200, min_length=50)[0]['summary_text'] # 可以调整长度\n",
        "        return summary\n",
        "    except:\n",
        "      return \"Summary Failed\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 替换成你想要爬取的网页链接\n",
        "    url = \"https://2024.aclweb.org/program/main_conference_papers/\"\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()\n",
        "    html_content = response.text\n",
        "\n",
        "    query = \"多模态关系抽取\"\n",
        "\n",
        "    call_llm = CallLLM()\n",
        "    llm_model = Model(\"THUDM/glm-4-9b-chat\", call_llm)\n",
        "    filtered_papers = extract_relevant_papers_with_llm(html_content, query, llm_model)\n",
        "    print(f\"Found {len(filtered_papers)} relevant papers using LLM.\")\n",
        "\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\") # 使用 BART 模型进行摘要\n",
        "\n",
        "    for paper in filtered_papers:\n",
        "        print(f\"Title: {paper['title']}\")\n",
        "        print(f\"Authors: {paper['authors']}\")\n",
        "        paper_content = search_paper_content(paper['title'])\n",
        "        if paper_content:\n",
        "            summary = summarize_paper_content(paper_content, summarizer)\n",
        "            print(f\"Summary: {summary}\")\n",
        "        else:\n",
        "           print(\"Paper Content Not Found\")\n",
        "        print(\"-\" * 40)"
      ]
    }
  ]
}