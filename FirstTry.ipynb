{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FirstTry.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPa6WZPF+IdUWUjH6FJHZCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/njucs/notebook/blob/master/FirstTry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJsK425nKc6t"
      },
      "source": [
        "### **准备工作**\n",
        "\n",
        "import 导入模块，每次使用模块中的函数都要是定是哪个模块。 from … import * 导入模块，每次使用模块中的函数，直接使用函数就可以了；注因为已经知道该函数是那个模块中的了。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eohcOUEguDnu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "import torchvision as tv\n",
        "from torchvision import models,transforms,datasets"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lAXq9YaMbuU"
      },
      "source": [
        "### **一些小技巧**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI5uh3_SujW8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4a6fd7-2d75-4766-b4cc-5d45b868f571"
      },
      "source": [
        "# 查看Python解释器\n",
        "import sys\n",
        "print(sys.executable)\n",
        "\n",
        "# 测试GPU是否可用\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Using gpu: %s ' % torch.cuda.is_available())\n",
        "use_gpu = torch.cuda.is_available()\n",
        "\n",
        "# 把Tensor转成Image，方便可视化\n",
        "'''\n",
        "from torchvision.transforms import ToPILImage\n",
        "show = ToPILImage()\n",
        "\n",
        "x = torch.randn(300,500)\n",
        "show(x)#.resize((100, 100))\n",
        "'''"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/bin/python3\n",
            "Using gpu: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpsShNc8JzaY"
      },
      "source": [
        "### **数据加载和预处理**\n",
        "**Dataset**对象是一个数据集，可以按下标访问，返回形如(data, label)的数据。\n",
        "\n",
        "**Dataloader**是一个可迭代的对象，它将dataset返回的每一条数据拼接成一个batch，并提供多线程加速优化和数据打乱等操作。当程序对dataset的所有数据遍历完一遍之后，相应的对Dataloader也完成了一次迭代。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vJo3M5EJ3FR"
      },
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# 定义对数据的预处理\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(), # 转为Tensor\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化\n",
        "                             ])\n",
        "\n",
        "# 训练集\n",
        "trainset = tv.datasets.CIFAR10(\n",
        "                    root='./data/tmp/', \n",
        "                    train=True, \n",
        "                    download=True,\n",
        "                    transform=transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "                    trainset, \n",
        "                    batch_size=4,\n",
        "                    shuffle=True, \n",
        "                    num_workers=2)\n",
        "\n",
        "# 测试集\n",
        "testset = tv.datasets.CIFAR10(\n",
        "                    './data/tmp/',\n",
        "                    train=False, \n",
        "                    download=True, \n",
        "                    transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "                    testset,\n",
        "                    batch_size=4, \n",
        "                    shuffle=False,\n",
        "                    num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ssx2oMPAQvYU"
      },
      "source": [
        "# 可以查看一下部分数据内容\n",
        "'''\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next() # 返回4张图片及标签\n",
        "print(' '.join('%11s'%classes[labels[j]] for j in range(4)))\n",
        "show(tv.utils.make_grid((images + 1) / 2)).resize((400,100))\n",
        "#show(images[2]).resize((100,100))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dd07c6YN4mrs"
      },
      "source": [
        "### **定义网络**\n",
        "定义网络时，需要继承nn.Module，并实现它的forward方法，**把网络中具有可学习参数的层放在构造函数\\__init__中**。如果某一层(如ReLU)不具有可学习的参数，则既可以放在构造函数中，也可以不放，但建议不放在其中，而在forward中使用nn.functional代替。\n",
        "\n",
        "**只要在nn.Module的子类中定义了forward函数，backward函数就会自动被实现(利用autograd)**。在forward 函数中可使用任何tensor支持的函数，还可以使用if、for循环、print、log等Python语法，写法和标准的Python写法一致。\n",
        "\n",
        "torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。但如果只想输入一个样本，则用 input.unsqueeze(0)将batch_size设为１。即输入必须是N个samples，但N可以设为1。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWtNCYMn40KX"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        # nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
        "        # 下式等价于nn.Module.__init__(self)\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # 卷积层\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        \n",
        "        # 全连接层\n",
        "        self.fc1   = nn.Linear(16*5*5, 120)\n",
        "        self.fc2   = nn.Linear(120, 84)\n",
        "        self.fc3   = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        # reshape，‘-1’表示自适应\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "net = Net()\n",
        "print(net)\n",
        "\n",
        "if(use_gpu):\n",
        "    net = net.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRSqMvbS7JhM"
      },
      "source": [
        "### **查看网络的可学习参数**\n",
        "\n",
        "网络的可学习参数通过net.parameters()返回，net.named_parameters可同时返回可学习的参数及名称。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axx1SbE17ZLy"
      },
      "source": [
        "params = list(net.parameters())\n",
        "print(params)\n",
        "\n",
        "for name,parameters in net.named_parameters():\n",
        "    print(name,':',parameters.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djwNlqXOJ93f"
      },
      "source": [
        "### **定义损失函数和优化器**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g-mvpBjqP3A"
      },
      "source": [
        "# 损失函数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "'''\n",
        "criterion = nn.MSELoss() # 均方误差损失, 计算 output 和 target 之差的均方差.\n",
        "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数, 描述两个概率分布的差异, 当训练有 C 个类别的分类问题时很有效.\n",
        "criterion = nn.KLDivLoss() # 计算 input 和 target 之间的 KL 散度. KL 散度可用于衡量不同的连续分布之间的距离, 在连续的输出分布的空间上(离散采样)上进行直接回归时很有效.\n",
        "criterion = nn.BCELoss() # 二进制交叉熵损失 BCELoss. 二分类任务时的交叉熵计算函数. 注意目标的值的范围为0到1之间.\n",
        "criterion = nn.MultiLabelMarginLoss() # 多标签分类损失 MultiLabelMarginLoss\n",
        "criterion = nn.MultiLabelSoftMarginLoss() # 多标签 one-versus-all 损失\n",
        "criterion = nn.CosineEmbeddingLoss() # cosine 损失\n",
        "criterion = nn.MultiMarginLoss(p=1, margin=1.0) # 多类别分类的hinge损失\n",
        "criterion = nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, reduction='mean') # 三元组损失\n",
        "criterion = nn.NLLLoss() # 负对数似然损失. 用于训练 C 个类别的分类问题.\n",
        "'''\n",
        "\n",
        "# 优化器\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "'''\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.Adagrad(net.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0) # 一种自适应优化方法，是自适应的为各个参数分配不同的学习率\n",
        "optimizer = optim.RMSprop(net.parameters(), lr=0.01, alpha=0.99, eps=1e-08, weight_decay=0, momentum=0, centered=False) # 对Adagrad的一种改进，可缓解Adagrad学习率下降较快的问题\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False) # 结合了Momentum和RMSprop，并进行了偏差修正\n",
        "'''\n",
        "\n",
        "if(use_gpu):\n",
        "    criterion = criterion.cuda()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6022z_bJ3en"
      },
      "source": [
        "### **训练网络并更新网络参数**\n",
        "\n",
        "所有网络的训练流程都是类似的，不断地执行如下流程：\n",
        "\n",
        "1. 输入数据\n",
        "2. 前向传播+反向传播\n",
        "3. 更新参数"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttWPDj5Iqclt"
      },
      "source": [
        "torch.set_num_threads(8)\n",
        "for epoch in range(20):  \n",
        "    \n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        \n",
        "        # 输入数据\n",
        "        inputs, labels = data\n",
        "        if(use_gpu):\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        # 梯度清零\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward + backward \n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()   \n",
        "        \n",
        "        # 更新参数 \n",
        "        optimizer.step()\n",
        "        \n",
        "        # 打印log信息\n",
        "        # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999: # 每2000个batch打印一下训练状态\n",
        "            print('[%d, %5d] loss: %.3f' \\\n",
        "                  % (epoch+1, i+1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsc7w5qDqhjf"
      },
      "source": [
        "### **测试网络**\n",
        "测试部分看看效果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0hZawuKqsw7"
      },
      "source": [
        "'''\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next() # 一个batch返回4张图片\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "print('实际的label: ', ' '.join(\\\n",
        "            '%08s'%classes[labels[j]] for j in range(4)))\n",
        "show(tv.utils.make_grid(images / 2 - 0.5)).resize((400,100))\n",
        "\n",
        "# 计算图片在每个类别上的分数\n",
        "outputs = net(images)\n",
        "# 得分最高的那个类\n",
        "_, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "print('预测结果: ', ' '.join('%5s'\\\n",
        "            % classes[predicted[j]] for j in range(4)))\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNzYsEX4qxgm"
      },
      "source": [
        "完整的测试结果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkmmRG0rqvyv"
      },
      "source": [
        "correct = 0 # 预测正确的图片数\n",
        "total = 0 # 总共的图片数\n",
        "\n",
        "# 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        if(use_gpu):\n",
        "            images = images.cuda()\n",
        "        outputs = net(images)\n",
        "        if(use_gpu):\n",
        "            outputs = outputs.cpu()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}